# AI-Conversational-Assistant-

This project involves developing an AI Conversational Assistant that can understand and generate text-based responses while also incorporating Text-to-Speech (TTS) functionality to provide spoken output. The core AI model used is TinyLlama, deployed via Ollama, which is a lightweight and efficient large language model designed for conversational AI tasks.
![1](https://github.com/user-attachments/assets/f95828dc-5c93-4ee8-954a-05ec23933a2d)

Key Features
Conversational AI

Uses TinyLlama, a compact and optimized version of LLaMA, for efficient text generation.
Capable of answering queries, engaging in natural conversations, and providing contextual responses.
Supports multi-turn dialogue handling, ensuring a coherent conversation flow.
Text-to-Speech (TTS) Integration
![image](https://github.com/user-attachments/assets/729883b7-9166-43f3-85ca-39d10db2dea1)

Converts AI-generated text into natural-sounding speech using TTS libraries such as gTTS (Google Text-to-Speech), Coqui TTS, or VITS.
Provides voice-based interaction, making the assistant more accessible and user-friendly.
Lightweight and Efficient
![image](https://github.com/user-attachments/assets/5e2e6495-eaf8-4ad2-bf92-20a4399f71f6)

TinyLlama is optimized for low-resource devices, ensuring fast inference and low memory consumption.
Ideal for edge devices, local deployment, or cloud-based chatbot applications.
Customizable Responses

Can be fine-tuned or prompt-engineered for specific use cases, such as customer support, education, or personal assistants.
Supports context retention, improving the relevance of responses.
Deployment via Ollama

Ollama simplifies the management and deployment of LLMs, making it easy to run and interact with TinyLlama locally or in a server environment.
Provides API endpoints for integrating the chatbot into web apps, desktop applications, or embedded systems.
User Interface (Optional)

Can be integrated with Streamlit, Flask, or FastAPI for a web-based chat UI.
Includes a mic input feature for voice commands and a playback option for TTS-generated responses.
Tech Stack
![image](https://github.com/user-attachments/assets/de4278d1-517c-4d01-ba10-66663a9704d6)

LLM Engine: TinyLlama (via Ollama)
TTS Engine: gTTS, Coqui TTS, or VITS
Programming Language: Python
Frameworks : Streamlit
Deployment: Local machine
Use Cases
✅ AI-powered virtual assistants for customer support
✅ Voice-enabled educational chatbots
✅ Personal AI assistants for productivity
✅ Smart home voice control systems
✅ AI-driven interactive FAQ systems
